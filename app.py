import os
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage, ImageMessage
from openai import OpenAI, APIStatusError, APIConnectionError, AuthenticationError
import traceback
import time
import random
import base64
import requests
import redis # å°å…¥ redis åº«
import json # å°å…¥ json åº«ç”¨æ–¼åºåˆ—åŒ–æ•¸æ“š

app = Flask(__name__)

# ç’°å¢ƒè®Šæ•¸ï¼šå¾ Render æˆ– .env è‡ªå‹•æŠ“å–
line_channel_access_token = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")
line_channel_secret = os.getenv("LINE_CHANNEL_SECRET")
openai_api_key = os.getenv("OPENAI_API_KEY")
redis_url = os.getenv("REDIS_URL") # æ–°å¢ Redis URL ç’°å¢ƒè®Šæ•¸

# DEBUG: æª¢æŸ¥ç’°å¢ƒè®Šæ•¸æ˜¯å¦æ­£ç¢ºè®€å–
print(f"DEBUG: LINE_CHANNEL_ACCESS_TOKEN loaded: {'Yes' if line_channel_access_token else 'No'}")
print(f"DEBUG: LINE_CHANNEL_SECRET loaded: {'Yes' if line_channel_secret else 'No'}")
print(f"DEBUG: OPENAI_API_KEY loaded: {'Yes' if openai_api_key else 'No'}")
print(f"DEBUG: REDIS_URL loaded: {'Yes' if redis_url else 'No'}")

# åˆå§‹åŒ– LineBotApi å’Œ WebhookHandler
if line_channel_access_token and line_channel_secret:
    line_bot_api = LineBotApi(line_channel_access_token)
    handler = WebhookHandler(line_channel_secret)
else:
    print("ERROR: LINE_CHANNEL_ACCESS_TOKEN or LINE_CHANNEL_SECRET is missing. Please set environment variables.")
    line_bot_api = None # ç¢ºä¿æœªåˆå§‹åŒ–
    handler = None # ç¢ºä¿æœªåˆå§‹åŒ–

# åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
client = None
if openai_api_key:
    try:
        client = OpenAI(api_key=openai_api_key)
        print("DEBUG: OpenAI client initialized successfully.")
    except Exception as e:
        print(f"ERROR: Failed to initialize OpenAI client: {e}")
        traceback.print_exc()
        client = None
else:
    print("ERROR: OPENAI_API_KEY is missing. OpenAI related features will be disabled.")
    
# åˆå§‹åŒ– Redis å®¢æˆ¶ç«¯
r = None
if redis_url:
    try:
        r = redis.from_url(redis_url, decode_responses=True) # decode_responses=True è‡ªå‹•è§£ç¢¼ç‚ºå­—ç¬¦ä¸²
        # å˜—è©¦ ping Redis ç¢ºä¿é€£ç·šæ­£å¸¸
        r.ping()
        print("DEBUG: Redis client initialized and connected successfully.")
    except Exception as e:
        print(f"ERROR: Failed to initialize or connect to Redis client: {e}")
        traceback.print_exc()
else:
    print("WARNING: REDIS_URL is not set. Session management will not be persistent.")

# å¥åº·æª¢æŸ¥ç”¨
@app.route("/", methods=['GET'])
def home():
    print("DEBUG: Received GET / request (Health Check)")
    return "OK", 200

# LINE Webhook å°ˆç”¨è·¯å¾‘
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get("X-Line-Signature", "")
    body = request.get_data(as_text=True)

    print(f"DEBUG: Received POST /callback request. Raw Body (first 200 chars): {body[:200]}...")
    print(f"DEBUG: X-Line-Signature: {signature}")

    if handler is None:
        print("ERROR: LINE Bot Handler not initialized. Aborting 500.")
        abort(500)

    try:
        print("DEBUG: Attempting to handle webhook event with handler...")
        handler.handle(body, signature)
        print("DEBUG: Webhook event handled successfully by handler.")
    except InvalidSignatureError:
        print("ERROR: InvalidSignatureError - Signature verification failed. Check LINE Channel Secret in Render and LINE Developers.")
        traceback.print_exc()
        abort(400)
    except Exception as e:
        print(f"CRITICAL ERROR: An unexpected error occurred during handler.handle: {e}")
        traceback.print_exc()
        abort(500)

    return "OK"

# --- å…±ç”¨çš„å›è¦†é‚è¼¯ (å»¶é²å’Œåˆ†æ®µ) ---
def send_delayed_response(event, reply_text):
    messages_to_send = []
    
    # è¨ˆç®—å»¶é²æ™‚é–“ (å·²æ ¹æ“šæ‚¨çš„æ–°è¦æ±‚èª¿æ•´)
    reply_length = len(reply_text)
    delay_seconds = 0
    if reply_length <= 30:
        delay_seconds = random.uniform(3, 5) # 30å­—å…§ï¼š3-5ç§’
    elif 30 < reply_length <= 60:
        delay_seconds = random.uniform(5, 7) # 31-60å­—ï¼š5-7ç§’
    elif 60 < reply_length <= 100:
        delay_seconds = random.uniform(7, 9) # 61-100å­—ï¼š7-9ç§’
    else: # è¶…é100å­—ï¼Œä½¿ç”¨åŸºæ–¼100å­—çš„å»¶é²å†åŠ ä¸Šé¡å¤–æ™‚é–“ï¼Œä½†ä¸è¶…é30ç§’
        delay_seconds = random.uniform(7, 9) + ((reply_length - 100) / 50) * random.uniform(1, 2)
        delay_seconds = min(delay_seconds, 30) # ç¢ºä¿å»¶é²ä¸è¶…é30ç§’

    print(f"DEBUG: Calculated initial reply delay: {delay_seconds:.2f} seconds for {reply_length} characters.")
    time.sleep(delay_seconds) # åŸ·è¡Œå»¶é²

    # --- START MODIFICATION: åˆªé™¤è¨Šæ¯åˆ†æ®µé‚è¼¯ ---
    # messages_to_send å°‡åªåŒ…å«ä¸€æ¢å®Œæ•´çš„è¨Šæ¯
    messages_to_send.append(TextSendMessage(text=reply_text.strip()))
    # --- END MODIFICATION ---

    # æ–°å¢ debug log ä¾†é©—è­‰ messages_to_send çš„å…§å®¹å’Œé•·åº¦
    print(f"DEBUG: Preparing to send {len(messages_to_send)} messages.")
    if messages_to_send:
        print(f"DEBUG: First message text content: {messages_to_send[0].text[:50]}...") # åªå°å‰50å­—
    else:
        print("DEBUG: messages_to_send is empty!")

    # ç™¼é€å›è¦†
    try:
        if line_bot_api is None:
            print("ERROR: line_bot_api is not initialized. Cannot reply.")
            return

        print(f"DEBUG: Final reply messages to send: {len(messages_to_send)} messages for reply token: {event.reply_token}.")
        line_bot_api.reply_message(
            event.reply_token,
            messages_to_send
        )
        print("DEBUG: Reply sent successfully to LINE.")
    except Exception as e:
        print(f"ERROR: Failed to reply to LINE user: {e}.")
        traceback.print_exc()


# --- è™•ç†æ–‡å­—è¨Šæ¯ ---
@handler.add(MessageEvent, message=TextMessage)
def handle_text_message(event):
    user_id = event.source.user_id # ç²å–ç”¨æˆ¶ ID
    user_input = event.message.text
    print(f"DEBUG: ğŸ§¾ Received text message from user {user_id}: '{user_input}'")

    # é è¨­å›è¦†ï¼Œä»¥é˜²ä»»ä½•éŒ¯èª¤
    reply_text = "ç›®å‰ç„¡æ³•å›è¦†ï¼Œè«‹ç¨å¾Œå†è©¦ ğŸ§˜" 

    if not client:
        print("ERROR: OpenAI client is not initialized. Cannot call GPT.")
        send_delayed_response(event, reply_text)
        return

    # æª¢æŸ¥æ˜¯å¦æœ‰å¾…è™•ç†çš„åœ–ç‰‡ (ä¾†è‡ª Redis)
    pending_image_data_str = None
    if r:
        try:
            pending_image_data_str = r.get(f"pending_image:{user_id}")
            print(f"DEBUG: Checking Redis for pending image for user {user_id}: {pending_image_data_str is not None}")
        except Exception as redis_e:
            print(f"ERROR: Failed to get pending image from Redis for user {user_id}: {redis_e}")
            traceback.print_exc()
            # å¦‚æœ Redis éŒ¯èª¤ï¼Œç•¶ä½œæ²’æœ‰å¾…è™•ç†åœ–ç‰‡
            pending_image_data_str = None
            
    if pending_image_data_str:
        # ç”¨æˆ¶ç™¼é€äº†æ–‡å­—ï¼Œä¸”æœ‰å¾…è™•ç†åœ–ç‰‡
        # åˆ¤æ–·ç”¨æˆ¶æ˜¯å¦åœ¨è©¢å•åœ–ç‰‡ç›¸é—œå…§å®¹ï¼Œä¾‹å¦‚ç†±é‡
        print(f"DEBUG: User {user_id} has a pending image. Checking text intent for image.")
        
        # å®šç¾©è§¸ç™¼åœ–ç‰‡åˆ†æçš„é—œéµå­—
        image_analysis_keywords = ["ç†±é‡", "å¡è·¯é‡Œ", "ç®—", "ä¼°", "åˆ†æ", "çœ‹", "é€™æ˜¯ä»€éº¼", "ç…§ç‰‡", "åœ–"]
        
        # åˆ¤æ–·ç”¨æˆ¶æ–‡å­—æ˜¯å¦åŒ…å«åœ–ç‰‡åˆ†ææ„åœ–
        is_image_analysis_intent = False
        if any(keyword in user_input for keyword in image_analysis_keywords):
            is_image_analysis_intent = True
        
        if is_image_analysis_intent:
            print(f"DEBUG: User {user_id} intends to analyze pending image.")
            # æ¸…é™¤å¾…è™•ç†åœ–ç‰‡æ¨™è¨˜ï¼Œé¿å…é‡è¤‡è™•ç†
            if r:
                try:
                    r.delete(f"pending_image:{user_id}")
                    print(f"DEBUG: Pending image deleted from Redis for user {user_id}.")
                except Exception as redis_e:
                    print(f"ERROR: Failed to delete pending image from Redis for user {user_id}: {redis_e}")
                    traceback.print_exc()

            try:
                pending_image_data = json.loads(pending_image_data_str)
                base64_image = pending_image_data['base64_image']
                
                # --- START MODIFICATION FOR TEXT HANDLER'S VISION PROMPT ---
                print("DEBUG: Calling GPT-4o for image analysis from text handler...")
                vision_system_prompt_for_text_handler = """
                ä½ æ˜¯ä¸€ä½å‹å–„ä¸”å°ˆæ¥­çš„ç‡Ÿé¤Šå¸«åŠ©ç†ï¼Œå°ˆç²¾æ–¼åˆ†æé£Ÿç‰©åœ–ç‰‡çš„ç‡Ÿé¤Šæˆåˆ†ã€‚
                è«‹æ ¹æ“šåœ–ç‰‡ä¸­çš„é£Ÿç‰©ï¼Œæä¾›ä»¥ä¸‹è©³ç´°çš„ç‡Ÿé¤Šåˆ†æï¼š

                1.  **åˆ†é …ç‡Ÿé¤Šç´ èˆ‡ä»½é‡ä¼°è¨ˆï¼š**
                    -   è«‹åˆ—å‡ºåœ–ç‰‡ä¸­æ‰€æœ‰å¯è­˜åˆ¥çš„é£Ÿç‰©é …ç›®ã€‚
                    -   å°æ–¼æ¯å€‹é£Ÿç‰©é …ç›®ï¼Œè«‹æ ¹æ“š**å°ç£çš„é£²é£ŸæŒ‡å—**ï¼Œå°‡å…¶æ­¸é¡åˆ°ã€Œå…­å¤§é¡é£Ÿç‰©ã€ï¼š**å…¨ç©€é›œç³§é¡ã€è±†é­šè›‹è‚‰é¡ã€ä¹³å“é¡ã€è”¬èœé¡ã€æ°´æœé¡ã€æ²¹è„‚èˆ‡å …æœç¨®å­é¡**ã€‚
                    -   ä¼°è¨ˆæ¯ç¨®é£Ÿç‰©çš„**ä»½é‡**ï¼Œä¸¦ç›¡é‡ä½¿ç”¨å®¹æ˜“ç†è§£çš„æ—¥å¸¸æ¯”å–»ï¼ˆä¾‹å¦‚ï¼šæ‹³é ­å¤§å°ã€æŒå¿ƒå¤§å°ã€ä¸€ç¢—ã€ä¸€å€‹é¦¬å…‹æ¯ç­‰ï¼‰ï¼Œè€Œä¸æ˜¯æ¨¡ç³Šçš„ã€Œä¸­ç­‰ã€ã€ã€Œé©é‡ã€æˆ–ã€Œä»½ã€ã€‚
                    -   ä¼°è¨ˆæ¯ç¨®é£Ÿç‰©æ‰€æä¾›çš„**ç†±é‡ (å¡è·¯é‡Œ)**ã€‚

                2.  **ç¸½ç†±é‡åŠ ç¸½ï¼š**
                    -   è¨ˆç®—ä¸¦æä¾›é€™ä»½é¤é»çš„**ç¸½ç†±é‡ç²—ä¼°å€¼**ã€‚

                3.  **æ•´é«”å›è¦†æ ¼å¼ï¼š**
                    -   **ç¬¬ä¸€æ®µ (ç°¡æ½”ç¸½çµ)ï¼š** ç›´æ¥çµ¦å‡ºé€™ä»½é¤é»çš„**ç¸½ç†±é‡ç²—ä¼°å€¼**ï¼Œä¾‹å¦‚ï¼šã€Œé€™ä»½é¤é»å¤§ç´„XXXå¡ã€‚ã€é€™æ®µè©±æ‡‰ç°¡çŸ­æœ‰åŠ›ï¼Œä¸å¸¶ä»»ä½•è¡¨æƒ…ç¬¦è™Ÿï¼Œä¹Ÿä¸åŒ…å«ç´°ç¯€åˆ†æã€‚
                    -   **ç¬¬äºŒæ®µ (è©³ç´°èªªæ˜)ï¼š** åœ¨ç¬¬ä¸€æ®µä¹‹å¾Œï¼Œè«‹æ›è¡Œä¸¦åˆ—å‡ºåœ–ç‰‡ä¸­æ‰€æœ‰é£Ÿç‰©çš„**å…­å¤§é¡åˆ†é¡ã€ä¼°è¨ˆä»½é‡ã€å–®é …ç†±é‡**ã€‚è«‹ä½¿ç”¨æ¸…æ™°çš„æ¢åˆ—å¼æˆ–æ®µè½ï¼Œè®“è³‡è¨Šä¸€ç›®ç­ç„¶ã€‚
                    -   å›è¦†è«‹ç”¨å£èªåŒ–ã€ç°¡æ½”è‡ªç„¶çš„èªæ°£ï¼Œå°±åƒåœ¨ LINE ä¸Šèˆ‡æœ‹å‹ç°¡çŸ­èŠå¤©ä¸€æ¨£ã€‚
                    -   **éå¸¸é‡è¦ï¼šæ•´å€‹å›è¦†è«‹å‹¿ä½¿ç”¨ä»»ä½•é–‹å ´ç™½ã€å•å€™èªæˆ–çµå°¾èªï¼Œä¾‹å¦‚ã€å˜¿ã€ã€ã€å“ˆå›‰ã€ã€ã€æ‚¨å¥½ã€ã€ã€æœ‰å•é¡Œå†å•æˆ‘å–”ã€ã€ã€å¸Œæœ›æœ‰å¹«åŠ©ã€ã€ã€æ„Ÿè¬ã€ã€ã€éœ€è¦å…¶ä»–å¹«åŠ©å—ï¼Ÿã€ç­‰ã€‚**
                """
                vision_response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": vision_system_prompt_for_text_handler},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                            ]
                        }
                    ],
                    max_tokens=500, # å¢åŠ  max_tokens ä»¥å…è¨±æ›´è©³ç´°çš„å›è¦†
                    temperature=0.7 
                )
                # --- END MODIFICATION FOR TEXT HANDLER'S VISION PROMPT ---
                reply_text = vision_response.choices[0].message.content.strip()
                send_delayed_response(event, reply_text)

            except AuthenticationError as e:
                print(f"ERROR: OpenAI Authentication Error: {e}. Check your API key and billing status.")
                reply_text = "GPT é©—è­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥ API é‡‘é‘°å’Œå¸³æˆ¶ã€‚ğŸ”"
                traceback.print_exc()
                send_delayed_response(event, reply_text)
            except (APIStatusError, APIConnectionError) as e:
                print(f"ERROR: OpenAI API Status/Connection Error for Vision: {e}. An issue occurred with OpenAI's servers or network.")
                reply_text = "åœ–ç‰‡åˆ†ææœå‹™æš«æ™‚ä¸ç©©å®šï¼Œè«‹ç¨å¾Œå†è©¦ã€‚ğŸŒ"
                traceback.print_exc()
                send_delayed_response(event, reply_text)
            except Exception as e:
                print(f"ERROR: âŒ An unexpected error occurred during GPT Vision call: {e}.")
                traceback.print_exc()
                reply_text = "æŠ±æ­‰ï¼Œåˆ†æåœ–ç‰‡æ™‚é‡åˆ°å•é¡Œï¼Œè«‹ç¨å¾Œå†è©¦ã€‚ğŸ˜¢"
                send_delayed_response(event, reply_text)
            
            return # è™•ç†å®Œåœ–ç‰‡ç›¸é—œè«‹æ±‚å¾Œå°±è¿”å›

        else: # æœ‰å¾…è™•ç†åœ–ç‰‡ï¼Œä½†ç”¨æˆ¶æ–‡å­—èˆ‡åœ–ç‰‡åˆ†æç„¡é—œ
            print(f"DEBUG: User {user_id} has pending image, but text is not about image analysis. Replying with reminder.")
            # èª¿æ•´èªæ°£ï¼Œæ›´è‡ªç„¶ã€ä¸é‚£éº¼ã€Œå·´çµã€
            reply_text = "å—¯ï¼Ÿé€™æ¢è¨Šæ¯å¥½åƒä¸æ˜¯åœ¨å•ç…§ç‰‡çš„å•é¡Œè€¶ï¼å¦‚æœä½ æƒ³å•ç…§ç‰‡ï¼Œè¨˜å¾—å‘Šè¨´æˆ‘å–”ã€‚ä¸ç„¶æˆ‘å¯ä»¥å›ç­”å…¶ä»–é—œæ–¼ç‡Ÿé¤Šæˆ–å¥åº·çš„å•é¡Œå•¦ï¼"
            send_delayed_response(event, reply_text)
            return # è™•ç†å®Œæé†’å¾Œå°±è¿”å›

    # ----------------------------------------------------------------
    # å¦‚æœæ²’æœ‰å¾…è™•ç†åœ–ç‰‡ï¼Œæˆ–è€…æ–‡å­—èˆ‡åœ–ç‰‡ç„¡é—œï¼Œå‰‡åŸ·è¡Œæ–‡å­—è™•ç†é‚è¼¯
    # ----------------------------------------------------------------
    try:
        print(f"DEBUG: Stage 1 (Text): Classifying '{user_input}' intent.")
        # æ”¹è®Šåˆ¤æ–·å™¨çš„æç¤ºè©ï¼Œè®“å®ƒå›è¦†å¤šç¨®é¡å‹
        judgment_response = client.chat.completions.create(
            model="gpt-3.5-turbo", 
            messages=[
                {"role": "system", "content": """ä½ æ˜¯ä¸€å€‹è¨Šæ¯åˆ†é¡å™¨ã€‚è«‹åˆ¤æ–·ç”¨æˆ¶çš„è¨Šæ¯å±¬æ–¼ä»¥ä¸‹å“ªä¸€ç¨®é¡å‹ï¼š
                - ã€ç‡Ÿé¤Š/å¥åº·ç›¸é—œã€ï¼šç›´æ¥æå•ç‡Ÿé¤Šã€é£²é£Ÿã€ç†±é‡ã€æ¸›é‡ç­‰äº‹å¯¦æ€§æˆ–å»ºè­°æ€§å…§å®¹ã€‚
                - ã€æƒ…ç·’/é–’èŠ/éç‡Ÿé¤Šæå•ã€ï¼šè¡¨é”æƒ…ç·’ï¼ˆå¦‚æ²®å–ªã€é–‹å¿ƒï¼‰ã€åˆ†äº«ç”Ÿæ´»æ—¥å¸¸ï¼Œæˆ–æ˜¯èˆ‡ç‡Ÿé¤Šå¥åº·ä¸»é¡Œç„¡é—œä½†ä»æƒ³èˆ‡äººèŠå¤©çš„å…§å®¹ã€‚
                - ã€ç„¡é—œã€ï¼šèˆ‡ç‡Ÿé¤Šå¥åº·ä¸»é¡Œå®Œå…¨ç„¡é—œï¼Œä¹Ÿä¸æ˜¯è¡¨é”æƒ…ç·’æˆ–æƒ³èŠå¤©çš„å…§å®¹ï¼ˆä¾‹å¦‚éš¨æ„æ‰“å­—ã€å»£å‘Šï¼‰ã€‚

                åªå›è¦†åˆ†é¡åç¨±ï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚
                """},
                {"role": "user", "content": user_input}
            ],
            temperature=0 # åˆ¤æ–·æ™‚ï¼Œæº«åº¦è¨­ç‚º 0ï¼Œç¢ºä¿æœ€ç¢ºå®šæ€§çš„å›è¦†
        )
        judgment_category = judgment_response.choices[0].message.content.strip()
        print(f"DEBUG: Judgment result: '{judgment_category}'")

        if judgment_category == 'ç‡Ÿé¤Š/å¥åº·ç›¸é—œ':
            print(f"DEBUG: Stage 2 (Text): Question is nutrition related. Generating detailed response for: '{user_input}'")
            # ç‡Ÿé¤Šå¸«ä¸»é«”å›è¦†é‚è¼¯
            system_prompt_content = """
            ä½ æ˜¯ä¸€ä½å‹å–„ã€å°ˆæ¥­çš„ç‡Ÿé¤Šå¸«åŠ©ç†ã€‚
            è«‹ä»¥å£èªåŒ–ã€ç°¡æ½”è‡ªç„¶çš„èªæ°£é€²è¡Œå›è¦†ï¼Œå°±åƒåœ¨ LINE ä¸Šèˆ‡æœ‹å‹ç°¡çŸ­èŠå¤©ä¸€æ¨£ã€‚
            **éå¸¸é‡è¦ï¼šå›è¦†å‹™å¿…ç°¡æ½”ï¼Œç›´æ¥å›ç­”å•é¡Œæ ¸å¿ƒï¼Œè«‹å‹¿ä½¿ç”¨ä»»ä½•é–‹å ´ç™½ã€å•å€™èªæˆ–çµå°¾èªï¼Œä¾‹å¦‚ã€å˜¿ã€ã€ã€å“ˆå›‰ã€ã€ã€æ‚¨å¥½ã€ã€ã€æœ‰å•é¡Œå†å•æˆ‘å–”ã€ã€ã€å¸Œæœ›æœ‰å¹«åŠ©ã€ã€ã€æ„Ÿè¬ã€ã€ã€éœ€è¦å…¶ä»–å¹«åŠ©å—ï¼Ÿã€ç­‰ï¼Œç›´æ¥æä¾›è³‡è¨Šå³å¯ã€‚é™¤éå¿…è¦ï¼Œå¦å‰‡ä¸éœ€è¦éåº¦ä½¿ç”¨è¡¨æƒ…ç¬¦è™Ÿã€‚**
            åœ¨å›ç­”æ™‚ï¼Œæä¾›å°ˆæ¥­çš„ç‡Ÿé¤ŠçŸ¥è­˜ï¼Œé¿å…ç”Ÿç¡¬çš„å°ˆæ¥­è¡“èªã€‚
            **åœ¨æè¿°é£Ÿç‰©ä»½é‡æ™‚ï¼Œè«‹ç›¡é‡ä½¿ç”¨å®¹æ˜“ç†è§£çš„æ—¥å¸¸æ¯”å–»ï¼ˆä¾‹å¦‚ï¼šæ‹³é ­å¤§å°ã€æŒå¿ƒå¤§å°ã€ä¸€ç¢—ã€ä¸€å€‹é¦¬å…‹æ¯ç­‰ï¼‰ï¼Œè€Œä¸æ˜¯æ¨¡ç³Šçš„ã€Œä¸­ç­‰ã€æˆ–ã€Œé©é‡ã€ã€‚**
            """
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt_content},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.7,
                max_tokens=250 
            )
            print(f"DEBUG: ğŸ‰ OpenAI GPT-4o API call successful. Full response: {response}")
            reply_text = response.choices[0].message.content.strip()
            print(f"DEBUG: Generated reply text: '{reply_text}'")
            send_delayed_response(event, reply_text)

        elif judgment_category == 'æƒ…ç·’/é–’èŠ/éç‡Ÿé¤Šæå•':
            print(f"DEBUG: Stage 2 (Text): Question is emotional/chat. Generating sympathetic response for: '{user_input}'")
            # æ–°å¢çš„æƒ…ç·’/é–’èŠå›è¦†é‚è¼¯ï¼Œå¼·èª¿ç°¡æ½”
            sympathy_prompt_content = """
            ä½ æ˜¯ä¸€ä½å‹å–„ã€è²¼å¿ƒä¸”æ”¯æŒæ€§çš„ç‡Ÿé¤Šå¸«åŠ©ç†ï¼Œä»¥**æ¥µç‚ºç°¡æ½”**çš„æ–¹å¼å›æ‡‰ã€‚
            ç”¨æˆ¶æ­£åœ¨è¡¨é”æƒ…ç·’æˆ–åˆ†äº«æ—¥å¸¸ï¼Œè«‹çµ¦äºˆ**ç°¡çŸ­ä¸”ç›´æ¥**çš„æ”¯æŒã€ç†è§£æˆ–é¼“å‹µï¼Œå°±åƒä½ åœ¨ LINE ä¸Šå°æœ‹å‹èªªä¸€å¥æš–å¿ƒçš„è©±ã€‚
            ä¿æŒåŒç†å¿ƒå’Œé¼“å‹µçš„èªæ°£ã€‚å¦‚æœèªå¥å…§å®¹éš±å«å°æ¸›é‡æˆ–å¥åº·çš„æ²®å–ªï¼Œå¯ä»¥çµ¦äºˆæ­£å‘é¼“å‹µã€‚
            **éå¸¸é‡è¦ï¼šå›è¦†å‹™å¿…æ¥µå…¶ç°¡æ½”ï¼ˆç›®æ¨™åœ¨20-40å­—å…§å®Œæˆï¼‰ï¼Œç›´æ¥å›ç­”æ ¸å¿ƒæƒ…ç·’æˆ–å…§å®¹ï¼Œè«‹å‹¿ä½¿ç”¨ä»»ä½•é–‹å ´ç™½ã€å•å€™èªæˆ–çµå°¾èªï¼Œä¾‹å¦‚ã€å˜¿ã€ã€ã€å“ˆå›‰ã€ã€ã€æ‚¨å¥½ã€ã€ã€æœ‰å•é¡Œå†å•æˆ‘å–”ã€ã€ã€å¸Œæœ›æœ‰å¹«åŠ©ã€ã€ã€æ„Ÿè¬ã€ã€ã€éœ€è¦å…¶ä»–å¹«åŠ©å—ï¼Ÿã€ç­‰ã€‚é¿å…éåº¦ä½¿ç”¨è¡¨æƒ…ç¬¦è™Ÿã€‚**
            """
            sympathy_response = client.chat.completions.create(
                model="gpt-4o", # æƒ…æ„Ÿå›è¦†ä¹Ÿç”¨4oï¼Œèªæ°£æœƒæ›´è‡ªç„¶
                messages=[
                    {"role": "system", "content": sympathy_prompt_content},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.7, # ç¨å¾®é™ä½æº«åº¦ï¼Œè®“èªæ°£æ›´è‡ªç„¶ã€å…§å®¹æ›´èšç„¦
                max_tokens=100 # é€™é¡å›è¦†ä¸éœ€è¦å¤ªé•·
            )
            reply_text = sympathy_response.choices[0].message.content.strip()
            print(f"DEBUG: Generated sympathetic reply text: '{reply_text}'")
            send_delayed_response(event, reply_text)

        elif judgment_category == 'ç„¡é—œ':
            print(f"DEBUG: Stage 2 (Text): Question is NOT nutrition related. Replying with random positive emoji.")
            # çœŸæ­£ç„¡é—œçš„å›è¦†é‚è¼¯ï¼Œç¶­æŒè¡¨æƒ…ç¬¦è™Ÿ
            positive_emojis = ["ğŸ˜Š", "ğŸ‘", "âœ¨", "ğŸŒ¸", "ğŸ’¡", "ğŸ’–", "ğŸŒŸ", "ğŸ™Œ", "ğŸ™‚"]
            reply_text_emoji = random.choice(positive_emojis)
            try:
                if line_bot_api is None:
                    print("ERROR: line_bot_api is not initialized. Cannot reply with emoji.")
                    return
                line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text_emoji))
            except Exception as e:
                print(f"ERROR: Failed to reply with emoji: {e}.")
                traceback.print_exc()
        else: # è™•ç†æœªçŸ¥çš„åˆ†é¡çµæœ
            print(f"WARNING: Unexpected judgment category: '{judgment_category}'. Falling back to generic reply.")
            reply_text = "æŠ±æ­‰ï¼Œæˆ‘é‚„ä¸å¤ªæ˜ç™½æ‚¨çš„æ„æ€ï¼Œæ‚¨å¯ä»¥å†èªªæ¸…æ¥šä¸€é»å—ï¼Ÿ"
            send_delayed_response(event, reply_text)

    except AuthenticationError as e:
        print(f"ERROR: OpenAI Authentication Error: {e}. Check your API key and billing status.")
        reply_text = "GPT é©—è­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥ API é‡‘é‘°å’Œå¸³æˆ¶ã€‚ğŸ”"
        traceback.print_exc()
        send_delayed_response(event, reply_text)
    except (APIStatusError, APIConnectionError) as e:
        print(f"ERROR: OpenAI API Status/Connection Error: {e}. An issue occurred with OpenAI's servers or network.")
        reply_text = "GPT æœå‹™æš«æ™‚ä¸ç©©å®šï¼Œè«‹ç¨å¾Œå†è©¦ã€‚ğŸŒ"
        traceback.print_exc()
        send_delayed_response(event, reply_text)
    except Exception as e:
        print(f"ERROR: âŒ An unexpected error occurred during GPT call: {e}.")
        traceback.print_exc()
        reply_text = "ç›®å‰ç„¡æ³•å›è¦†ï¼Œè«‹ç¨å¾Œå†è©¦ ğŸ§˜"
        send_delayed_response(event, reply_text)

# --- è™•ç†åœ–ç‰‡è¨Šæ¯ ---
@handler.add(MessageEvent, message=ImageMessage)
def handle_image_message(event):
    user_id = event.source.user_id # ç²å–ç”¨æˆ¶ ID
    print(f"DEBUG: >>> Entering handle_image_message function. User ID: {user_id}")
    
    reply_text = "æŠ±æ­‰ï¼Œåœ–ç‰‡è™•ç†æœå‹™ç›®å‰ç„¡æ³•ä½¿ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚ğŸ˜…"

    if not client:
        print("ERROR: OpenAI client is not initialized. Cannot process image.")
        send_delayed_response(event, reply_text)
        return

    try:
        # 1. ç²å–åœ–ç‰‡å…§å®¹ä¸¦ Base64 ç·¨ç¢¼
        message_content = line_bot_api.get_message_content(event.message.id)
        image_data = b''
        for chunk in message_content.iter_content():
            image_data += chunk
        base64_image = base64.b64encode(image_data).decode('utf-8')
        print(f"DEBUG: Image received and Base64 encoded for user {user_id}. Size: {len(base64_image)} bytes.")

        # 2. å°‡åœ–ç‰‡æ•¸æ“šå„²å­˜åˆ° Redisï¼Œä¸¦æ¨™è¨˜ç‚ºå¾…è™•ç†
        if r:
            # å„²å­˜ Base64 ç·¨ç¢¼çš„åœ–ç‰‡å’Œç›¸é—œä¿¡æ¯
            image_info = {"base64_image": base64_image}
            # è¨­å®š 5 åˆ†é˜éæœŸæ™‚é–“ (300 ç§’)ï¼Œå¦‚æœç”¨æˆ¶è¶…é 5 åˆ†é˜æ²’æœ‰æå•å°±å¿˜è¨˜é€™å¼µåœ–
            r.set(f"pending_image:{user_id}", json.dumps(image_info), ex=300) 
            print(f"DEBUG: Pending image saved to Redis for user {user_id}. Expires in 300s.")
            
            # ç°¡åŒ–åœ–ç‰‡ä¸Šå‚³çš„åˆæ­¥å›è¦†ï¼Œæ›´è‡ªç„¶
            initial_reply_text = "ç…§ç‰‡æ”¶åˆ°å›‰ã€‚è«‹å•æœ‰ä»€éº¼æƒ³å•çš„å—ï¼Ÿ" # ç§»é™¤è¡¨æƒ…ç¬¦è™Ÿï¼Œæ›´ç°¡æ½”
            send_delayed_response(event, initial_reply_text)
            return # ç¢ºä¿é€™è£¡æœ‰ returnï¼Œé¿å…å¾ŒçºŒä»£ç¢¼ç¹¼çºŒåŸ·è¡Œ

        else:
            print(f"WARNING: Redis not initialized. Cannot save pending image for user {user_id}. Image will be processed immediately without pending logic.")
            
            # --- START MODIFICATION FOR IMAGE HANDLER'S VISION PROMPT ---
            print("DEBUG: Calling GPT-4o for direct image analysis (Redis not available).")
            vision_system_prompt_for_image_handler = """
            ä½ æ˜¯ä¸€ä½å‹å–„ä¸”å°ˆæ¥­çš„ç‡Ÿé¤Šå¸«åŠ©ç†ï¼Œå°ˆç²¾æ–¼åˆ†æé£Ÿç‰©åœ–ç‰‡çš„ç‡Ÿé¤Šæˆåˆ†ã€‚
            è«‹æ ¹æ“šåœ–ç‰‡ä¸­çš„é£Ÿç‰©ï¼Œæä¾›ä»¥ä¸‹è©³ç´°çš„ç‡Ÿé¤Šåˆ†æï¼š

            1.  **åˆ†é …ç‡Ÿé¤Šç´ èˆ‡ä»½é‡ä¼°è¨ˆï¼š**
                -   è«‹åˆ—å‡ºåœ–ç‰‡ä¸­æ‰€æœ‰å¯è­˜åˆ¥çš„é£Ÿç‰©é …ç›®ã€‚
                -   å°æ–¼æ¯å€‹é£Ÿç‰©é …ç›®ï¼Œè«‹æ ¹æ“š**å°ç£çš„é£²é£ŸæŒ‡å—**ï¼Œå°‡å…¶æ­¸é¡åˆ°ã€Œå…­å¤§é¡é£Ÿç‰©ã€ï¼š**å…¨ç©€é›œç³§é¡ã€è±†é­šè›‹è‚‰é¡ã€ä¹³å“é¡ã€è”¬èœé¡ã€æ°´æœé¡ã€æ²¹è„‚èˆ‡å …æœç¨®å­é¡**ã€‚
                -   ä¼°è¨ˆæ¯ç¨®é£Ÿç‰©çš„**ä»½é‡**ï¼Œä¸¦ç›¡é‡ä½¿ç”¨å®¹æ˜“ç†è§£çš„æ—¥å¸¸æ¯”å–»ï¼ˆä¾‹å¦‚ï¼šæ‹³é ­å¤§å°ã€æŒå¿ƒå¤§å°ã€ä¸€ç¢—ã€ä¸€å€‹é¦¬å…‹æ¯ç­‰ï¼‰ï¼Œè€Œä¸æ˜¯æ¨¡ç³Šçš„ã€Œä¸­ç­‰ã€ã€ã€Œé©é‡ã€æˆ–ã€Œä»½ã€ã€‚
                -   ä¼°è¨ˆæ¯ç¨®é£Ÿç‰©æ‰€æä¾›çš„**ç†±é‡ (å¡è·¯é‡Œ)**ã€‚

            2.  **ç¸½ç†±é‡åŠ ç¸½ï¼š**
                -   è¨ˆç®—ä¸¦æä¾›é€™ä»½é¤é»çš„**ç¸½ç†±é‡ç²—ä¼°å€¼**ã€‚

            3.  **æ•´é«”å›è¦†æ ¼å¼ï¼š**
                -   **ç¬¬ä¸€æ®µ (ç°¡æ½”ç¸½çµ)ï¼š** ç›´æ¥çµ¦å‡ºé€™ä»½é¤é»çš„**ç¸½ç†±é‡ç²—ä¼°å€¼**ï¼Œä¾‹å¦‚ï¼šã€Œé€™ä»½é¤é»å¤§ç´„XXXå¡ã€‚ã€é€™æ®µè©±æ‡‰ç°¡çŸ­æœ‰åŠ›ï¼Œä¸å¸¶ä»»ä½•è¡¨æƒ…ç¬¦è™Ÿï¼Œä¹Ÿä¸åŒ…å«ç´°ç¯€åˆ†æã€‚
                -   **ç¬¬äºŒæ®µ (è©³ç´°èªªæ˜)ï¼š** åœ¨ç¬¬ä¸€æ®µä¹‹å¾Œï¼Œè«‹æ›è¡Œä¸¦åˆ—å‡ºåœ–ç‰‡ä¸­æ‰€æœ‰é£Ÿç‰©çš„**å…­å¤§é¡åˆ†é¡ã€ä¼°è¨ˆä»½é‡ã€å–®é …ç†±é‡**ã€‚è«‹ä½¿ç”¨æ¸…æ™°çš„æ¢åˆ—å¼æˆ–æ®µè½ï¼Œè®“è³‡è¨Šä¸€ç›®ç­ç„¶ã€‚
                -   å›è¦†è«‹ç”¨å£èªåŒ–ã€ç°¡æ½”è‡ªç„¶çš„èªæ°£ï¼Œå°±åƒåœ¨ LINE ä¸Šèˆ‡æœ‹å‹ç°¡çŸ­èŠå¤©ä¸€æ¨£ã€‚
                -   **éå¸¸é‡è¦ï¼šæ•´å€‹å›è¦†è«‹å‹¿ä½¿ç”¨ä»»ä½•é–‹å ´ç™½ã€å•å€™èªæˆ–çµå°¾èªï¼Œä¾‹å¦‚ã€å˜¿ã€ã€ã€å“ˆå›‰ã€ã€ã€æ‚¨å¥½ã€ã€ã€æœ‰å•é¡Œå†å•æˆ‘å–”ã€ã€ã€å¸Œæœ›æœ‰å¹«åŠ©ã€ã€ã€æ„Ÿè¬ã€ã€ã€éœ€è¦å…¶ä»–å¹«åŠ©å—ï¼Ÿã€ç­‰ã€‚**
            """
            vision_response = client.chat.completions.create(
                model="gpt-4o", 
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": vision_system_prompt_for_image_handler},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                        ]
                    }
                ],
                max_tokens=500, # å¢åŠ  max_tokens ä»¥å…è¨±æ›´è©³ç´°çš„å›è¦†
                temperature=0.7 
            )
            # --- END MODIFICATION FOR IMAGE HANDLER'S VISION PROMPT ---
            reply_text = vision_response.choices[0].message.content.strip()
            send_delayed_response(event, reply_text)
            return # è™•ç†å®Œç•¢ç›´æ¥è¿”å›ï¼Œå› ç‚ºæ²’æœ‰ç­‰å¾…é‚è¼¯

    except AuthenticationError as e:
        print(f"ERROR: OpenAI Authentication Error: {e}. Check your API key and billing status.")
        reply_text = "GPT é©—è­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥ API é‡‘é‘°å’Œå¸³æˆ¶ã€‚ğŸ”"
        traceback.print_exc()
        send_delayed_response(event, reply_text)
    except (APIStatusError, APIConnectionError) as e:
        print(f"ERROR: OpenAI API Status/Connection Error for Vision: {e}. An issue occurred with OpenAI's servers or network.")
        reply_text = "åœ–ç‰‡åˆ†ææœå‹™æš«æ™‚ä¸ç©©å®šï¼Œè«‹ç¨å¾Œå†è©¦ã€‚ğŸŒ"
        traceback.print_exc()
        send_delayed_response(event, reply_text)
    except Exception as e:
        print(f"ERROR: âŒ An unexpected error occurred during image processing: {e}.")
        traceback.print_exc()
        reply_text = "è™•ç†åœ–ç‰‡æ™‚é‡åˆ°å•é¡Œï¼Œè«‹ç¨å¾Œå†è©¦ ğŸ§˜"
        send_delayed_response(event, reply_text)
    
# æ­£ç¢ºçš„ Render å•Ÿå‹•æ–¹å¼ï¼šè®€å– port ä¸¦ç¶å®š 0.0.0.0
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    print(f"DEBUG: Starting Flask app on host 0.0.0.0, port {port}")
    app.run(host="0.0.0.0", port=port)
